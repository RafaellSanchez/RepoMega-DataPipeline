{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando sobre a planilha\n",
      "DataFrame criado\n",
      "Iterando sobre o df\n",
      "Salvando o df com delimitador ponto e virgula\n",
      "Nome do arquivo /workspaces/RepoMega-DataPipeline/data/files/full-data-megaMEGA SENA.txt\n"
     ]
    }
   ],
   "source": [
    "# Carregue o arquivo Excel\n",
    "file = '/workspaces/RepoMega-DataPipeline/data/xlsx/Mega-Sena.xlsx'\n",
    "path = '/workspaces/RepoMega-DataPipeline/data/files/'\n",
    "wb = openpyxl.load_workbook(filename=file)\n",
    "file_mg = f'full-data-mega'\n",
    "\n",
    "name = path + file_mg\n",
    "\n",
    "dict_dfs = {}\n",
    "\n",
    "time.sleep(3)\n",
    "print('Iterando sobre a planilha')\n",
    "# Iterar sobre as planilhas e criar DataFrames\n",
    "for sheet in wb.sheetnames:\n",
    "    sheet_data = []\n",
    "    for row in wb[sheet].iter_rows(values_only=True):\n",
    "        sheet_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(sheet_data[1:], columns=sheet_data[0])\n",
    "    dict_dfs[sheet] = df\n",
    "time.sleep(3)\n",
    "print('DataFrame criado')\n",
    "# Iterar sobre as planilhas no dicionário e salvar em arquivos de texto delimitados por ponto e vírgula\n",
    "for sheet_name, df in dict_dfs.items():\n",
    "    file_name = name + sheet_name + '.txt'\n",
    "    df.to_csv(file_name, sep=';', index=False)\n",
    "time.sleep(3)\n",
    "print('Iterando sobre o df')\n",
    "print('Salvando o df com delimitador ponto e virgula')\n",
    "print(f'Nome do arquivo {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando as variaveis...\n",
      "Listando o diretório\n",
      "Iterar sobre a variavel\n",
      "Arquivo full-data-megaMEGA SENA.txt, copiado para: /workspaces/RepoMega-DataPipeline/data/bckpFile/\n",
      "Código concluido.\n",
      "-------------------------\n",
      "Arquivo copiado full-data-megaMEGA SENA.txt\n",
      "-------------------------\n",
      "Iniciando o ETL\n",
      "-------------------------\n",
      "Inic prt 3 código\n",
      "-------------------------\n",
      "Carregando os dados\n",
      "Procurando arquivo no diretório pela palavra chave\n",
      "Iniciando a iteração dos dados!\n",
      "Arquivo salvo jogos_mega_filter_20231206_001341.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "#função para mensagem\n",
    "def mensagem(msg):\n",
    "    print('-' *25)\n",
    "    print(msg)\n",
    "    print('-' *25)\n",
    "    \n",
    "\n",
    "print('Carregando as variaveis...')\n",
    "path = '/workspaces/RepoMega-DataPipeline/data/files/'\n",
    "cp_path = '/workspaces/RepoMega-DataPipeline/data/bckpFile/'\n",
    "name = 'full-data-megaMEGA SENA.txt'\n",
    "\n",
    "time.sleep(3)\n",
    "print('Listando o diretório')\n",
    "print('Iterar sobre a variavel')\n",
    "list_path = os.listdir(path)\n",
    "\n",
    "for file_name in list_path:\n",
    "    if name in file_name:\n",
    "        src_file = os.path.join(path, file_name)\n",
    "        dest_file = os.path.join(cp_path, file_name)\n",
    "        shutil.copyfile(src_file, dest_file)\n",
    "        print(f'Arquivo {file_name}, copiado para: {cp_path}')\n",
    "print('Código concluido.')\n",
    "\n",
    "\n",
    "mensagem(f'Arquivo copiado {name}')\n",
    "\n",
    "'''\n",
    "ETL para tratamento da base 'Mega'\n",
    "'''\n",
    "print('Iniciando o ETL')\n",
    "\n",
    "mensagem('Inic prt 3 código')\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "print('Carregando os dados')\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# arquivo_full = '/workspaces/project-api/mega/metadados/data_analytics_20231008_173628.txt'\n",
    "timestamp_original = timestamp\n",
    "\n",
    "''''\n",
    "Dessa forma, o timestamp_original mantém o valor original do timestamp \n",
    "gerado no início do código, enquanto timestamp_arquivo armazena a data \n",
    "de modificação do arquivo, evitando assim a substituição acidental do \n",
    "valor original do timestamp que você deseja usar no nome do arquivo.\n",
    "'''\n",
    "\n",
    "print('Procurando arquivo no diretório pela palavra chave')\n",
    "time.sleep(3)\n",
    "# diretorio = '/workspaces/project-api/mega/dados/' \n",
    "# Substitua pelo caminho do seu diretório\n",
    "# diretorio = '/workspaces/project-api/mega/metadados/'\n",
    "\n",
    "diretorio = '/workspaces/RepoMega-DataPipeline/data/bckpFile/'\n",
    "palavra_chave = 'full-data'  \n",
    "# Substitua pela palavra-chave que você deseja encontrar\n",
    "ultimo_timestamp = None\n",
    "caminho_arquivo = None\n",
    "\n",
    "print('Iniciando a iteração dos dados!')\n",
    "time.sleep(3)\n",
    "for root, dirs, files in os.walk(diretorio):\n",
    "    for nome_arquivo in files:\n",
    "        if palavra_chave in nome_arquivo:\n",
    "            caminho_completo = os.path.join(root, nome_arquivo)\n",
    "            timestamp = os.path.getmtime(caminho_completo)\n",
    "            if ultimo_timestamp is None or timestamp > ultimo_timestamp:\n",
    "                ultimo_timestamp = timestamp\n",
    "                caminho_arquivo = caminho_completo\n",
    "\n",
    "if caminho_arquivo:\n",
    "    # Agora você tem o caminho completo do arquivo desejado na variável caminho_arquivo.\n",
    "    # Você pode manipulá-lo da seguinte forma:\n",
    "    # with open(caminho_arquivo, 'r') as arquivo:\n",
    "    #     conteudo = arquivo.read()\n",
    "    df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "    df_limp = df[df['Rateio 6 acertos'] != 'R$0,00']\n",
    "    paths = '/workspaces/RepoMega-DataPipeline/data/files/'\n",
    "    ffilter = 'jogos_mega_filter_' + str(timestamp_original) + '.txt'\n",
    "    \n",
    "    df_save = df_limp.to_csv(f'{paths}{ffilter}', sep=';')\n",
    "    print(f'Arquivo salvo {ffilter}')\n",
    "    # Faça o que desejar com o conteúdo do arquivo.\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(f'Nenhum arquivo correspondente à palavra-chave \"{palavra_chave}\" foi encontrado no diretório {diretorio}.')\n",
    "    \n",
    "# arquivo_full = df\n",
    "\n",
    "time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
